#include <ros/ros.h>
#include <cstdio>
#include <iostream>
#include <map>
#include <ostream>
#include <std_msgs/String.h>
#include <dirent.h>
#include <sys/types.h>
#include <opencv2/opencv.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/core/core.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/imgproc/types_c.h>

#include <cv_bridge/cv_bridge.h>
#include <sstream>
#include <skeleton_markers/RAS_Evidence.h>
#include <skeleton_markers/imagePosition.h>
#include <skeleton_markers/detectedObject.h>
#include <skeleton_markers/recognitionActionAction.h>

#include <image_transport/image_transport.h>

#include <actionlib/server/simple_action_server.h>
using std::cout;
using std::endl;

#define D(X) X

class object_recognition {
public:
    object_recognition() :
        _it(nh),
        server(nh, "object_recognition", false){
        img_path_sub = nh.subscribe("/object_recognition/imgpath", 1, &object_recognition::imgFileCB, this);
        imagedir = "/home/vibek/skeleton_markers/sample_images/";
        //img_sub = _it.subscribe("/object_detection/object",1, &object_recognition::recognitionCB,this);
        imgposition_sub = nh.subscribe("/object_detection/object_position",1, &object_recognition::recognitionCBpos,this);
        espeak_pub= nh.advertise<std_msgs::String>("/espeak/string",1);
        objectposition_pub = nh.advertise<skeleton_markers::detectedObject>("/object_recognition/detected_object",1);
        cv::namedWindow("Image_got_from_detection");
        lastobject= ros::Time::now();
        evidence_pub = nh.advertise<skeleton_markers::RAS_Evidence>("/evidence",1);
        std::fill_n(alreadyseen,10,0);
        std::fill_n(lastobjects,2,0);
        std::fill_n(Point,3,0);
        working=false;
        train_knn();
        server.registerGoalCallback(boost::bind(&object_recognition::goworking, this));
        server.registerPreemptCallback(boost::bind(&object_recognition::stopworking, this));
        server.start();
    }


// ########################## Callbacks #############################
    void goworking(){
        working=true;
	std::cout << "Got the comand to start working from main node " << std::endl;
        server.acceptNewGoal();
        //ros::Rate rate(1);

        std::fill_n(lastobjects,2,0);
        //server.setSucceeded();
    }
    void stopworking(){
        working=false;
        server.setPreempted();
    }

    void imgFileCB(const std_msgs::String& pathToImg) {
        D(cout << "Classifying " << pathToImg.data << endl;)
        cv::Mat inputImg = cv::imread(pathToImg.data);
        D(cout << "Loading Image done" << endl;)
        cv::cvtColor(inputImg,inputImg,CV_HSV2BGR);
        classification(inputImg);



    }
// For Normal Images:
    void recognitionCB(const sensor_msgs::ImageConstPtr& img_msg){

        //cout<< "got in CB"<< endl;

        cv_bridge::CvImagePtr cv_ptr;
        try {
            cv_ptr = cv_bridge::toCvCopy(img_msg, "bgr8");
        }
        catch (cv_bridge::Exception& e) {
            ROS_ERROR("cv_bridge exception: %s", e.what());
            return;
        }
        //cout<< "loaded pointer"<< endl;
        if(working){
        classification(cv_ptr->image);
        }
    }
// For Images with Poistion:
    void recognitionCBpos(const skeleton_markers::imagePosition& img_msg){

        //cout<< "got in CB"<< endl;

        cv_bridge::CvImagePtr cv_ptr;
        try {
            cv_ptr = cv_bridge::toCvCopy(img_msg.image, "bgr8");
        }
        catch (cv_bridge::Exception& e) {
            ROS_ERROR("cv_bridge exception: %s", e.what());
            return;
        }
        color= img_msg.color;
        if(0==color.compare(("orange"))) color="patric";
        Point[0]=img_msg.point.x;
        Point[1]=img_msg.point.y;
        Point[2]=img_msg.point.z;
        //cout<< "loaded pointer"<< endl;
        currentheader_= img_msg.header;
        if(working){
            classification(cv_ptr->image);
        }
}
 // ########################### Classification ##############################
    void classification(cv::Mat inputImg){
        cv::Mat showimage;
        cv::resize(inputImg,showimage,cv::Size(200,200));

        cv::cvtColor(inputImg,inputImg,CV_BGR2HSV);


        //Bluring
        cv::medianBlur(inputImg, inputImg, 9);

        cv::imshow("Image_got_from_detection",inputImg);
        cv::waitKey(1);
        cv::resize(inputImg,inputImg,cv::Size(sample_size_x,sample_size_y),cv::INTER_AREA);
        cv::Mat rowImg = matToFloatRow(inputImg);


        //PCA:
        cv::Mat pcaRowImg;
        pca.project(rowImg,pcaRowImg);

        cv::Mat res;
        //cout<< "Before PCA attributes " << rowImg.cols << "After PCA attributes " << pcaRowImg.cols << endl;

        cv::Mat neighborsclasses;
        cv::Mat neighborsdistant;
        kc.find_nearest(pcaRowImg, neighborcount, res,neighborsclasses,neighborsdistant);
        //float resbayes = bc.predict(pcaRowImg);

        int sureness=0;
        for(int i=0;i<neighborcount;i++){
            if(res.at<int>(0)==neighborsclasses.at<int>(0,i)){
                sureness++;
            }
        }
        //D(cout << "Amount of yes votes " << sureness << "  Out of "<< neighborcount<< endl;)
        //D(cout << "K-Nearest neighbor said : " << intToDesc[res.at<float>(0)] << "  <<" Given color: "<< color << endl;)
        int resultid = res.at<float>(0);
        std::string result;
        //std::string resultbayes = intToDesc[resbayes];
        std::string resultkn =intToDesc[resultid];
        ros::Time time = ros::Time::now();
        int matchingcolorkn = resultkn.find(color);
        //int matchingcolorbayes = resultbayes.find(color);
        if(matchingcolorkn >=0){
            result= resultkn;
            //D(std::cout << "All 2 have agreed" << std::endl;)
        }
//        else if(resultid == resbayes){
//            result= resultkn;
//            D(std::cout << " Bayes and KNN agreed, color was different" << std::endl;)
//        }
//        else if(matchingcolorbayes >=0 && matchingcolorkn >=0 ){
//            result = resultkn;
//            D(std::cout << "Color agree with both Bayes and KNN but different shape" << std::endl;)
//        }
//        else if(matchingcolorkn >=0){
//            result = resultkn;
//            D(std::cout << "Color and KNN Agreed" << std::endl;)
//        }

////        else if(matchingcolorbayes >=0){
////            result = resultbayes;
////            resultid=resbayes;
////            D(std::cout << "Color and Bayes Agreed" << std::endl;)
////        }
        else{
            //D(std::cout << "All 2 Classifier different " << std::endl;)
            result = "Object";
            resultid=-1;
        }
        if(0!=result.compare(("background")) && result.size()>0){
            if(lastobjects[0]==resultid && lastobjects[1]==resultid){
                if(resultid!=-1) alreadyseen[resultid]++;
                // Publishing Msg:
                D(std::cout << "Detected an " << result << std::endl;)
                skeleton_markers::detectedObject detection_msgs;
                detection_msgs.position.x= Point[0];
                detection_msgs.position.y= Point[1];
                detection_msgs.position.z= Point[2];
                detection_msgs.object_id = result;
                detection_msgs.header = currentheader_;
                objectposition_pub.publish(detection_msgs);
                // Publishing Evidence
                ras_msgs::RAS_Evidence evidence_msg;
                evidence_msg.stamp =ros::Time::now();
                evidence_msg.object_id = result;
                evidence_msg.group_number = 3;
                cv_bridge::CvImage sendingmsg = cv_bridge::CvImage(std_msgs::Header(),"bgr8",showimage);
                evidence_msg.image_evidence = sendingmsg.toImageMsg().operator *();
                evidence_pub.publish(evidence_msg);
                evidence_pub.publish(evidence_msg);
                evidence_pub.publish(evidence_msg);
                speakresult(result);
                lastobject = time;
                working=false;
                server.setSucceeded();

                }
            else{
                lastobjects[1]=lastobjects[0];
                lastobjects[0]=resultid;
            }
        }
        /*else if(time.sec-lastobject.sec >5 ){
            ras_msgs::RAS_Evidence msg;
            msg.stamp =ros::Time::now();
            msg.object_id = "Object";
            msg.group_number = 3;
            msg.image_evidence = cv_bridge::CvImage(std_msgs::Header(),"bgr8",showimage).toImageMsg().operator *() ;
            evidence_pub.publish(msg);
            speakresult("Object");
            lastobject = time;
        }*/

    }




 //############################## Train functions ####################################

    void trainPCA(cv::Mat& rowImg, cv::Mat& result){
        if(load){
            cv::FileStorage fs1("/home/ras/catkin_ws/src/object_recognition/launch/pca.yml", cv::FileStorage::READ);
            cv::Mat loadeigenvectors, loadeigenvalues , loadedmean;
            fs1["Eigenvalues"] >> loadeigenvalues;
            fs1["Eigenvector"] >> loadeigenvectors;
            fs1["Mean"] >> loadedmean;
            fs1.release();
            pca.mean=loadedmean.clone();
            pca.eigenvalues= loadeigenvalues.clone();
            pca.eigenvectors=loadeigenvectors.clone();
            pca.project(rowImg,result);
            std::cout << "Loaded succesfull! Cols left : " << result.cols << std::endl;
        }
        else{
            std::cout << " Rows before PCA " << rowImg.cols << std::endl;
            pca = cv::PCA(rowImg,cv::Mat(), CV_PCA_DATA_AS_ROW,pcaaccuracy);
            pca.project(rowImg,result);

            std::cout << " Rows after PCA " << result.cols << std::endl;
            if(save){
                cv::FileStorage fs("/home/ras/catkin_ws/src/object_recognition/launch/pca.yml", cv::FileStorage::WRITE);

                cv::Mat eigenval,eigenvec,mean;
                mean=pca.mean.clone();
                eigenval=pca.eigenvalues.clone();
                eigenvec=pca.eigenvectors.clone();
                fs << "Eigenvalues" << eigenval;
                fs << "Eigenvector" << eigenvec;
                fs << "Mean" << mean;
                fs.release();

            }
        }
    }

    void train_BayesClassifier(cv::Mat& traindata,cv::Mat& responses){
        bc.train(traindata,responses);
    }

    void train_knn(){
        std::vector<std::pair<std::string, std::vector<std::string> > > objects = readTestImagePaths(imagedir);
        cv::Mat trainData;
        cv::Mat responses;
        for(int i = 0; i < objects.size(); i++) {
            cout << objects[i].first << " = " << i << endl;
            intToDesc[i] = objects[i].first;
            std::vector<std::string>& vec = objects[i].second;
            for(int j = 0; j < vec.size(); j++) {
                responses.push_back(i);
                cv::Mat inputImg = cv::imread(imagedir + objects[i].first + "/" + vec[j]);
                cv::Mat rowImg = matToFloatRow(inputImg);
                trainData.push_back(rowImg);
            }
        }
        cv::Mat pcatrainData;
        trainPCA(trainData,pcatrainData);
        D(std::cout << "Try to train"<< std::endl;)
        kc.train(pcatrainData, responses);

        //BayesClassifier:
        //train_BayesClassifier(pcatrainData,responses);

        D(std::cout<< "Training succeded"<< std::endl;)
    }


    std::vector<std::pair<std::string, std::vector<std::string> > >
    readTestImagePaths(std::string directory) {
        std::vector<std::pair<std::string, std::vector<std::string> > > objects;
        DIR* dirPtr;
        dirent* entry;

        if((dirPtr = opendir(directory.c_str())) == NULL) {
            cout << "Could not open directory for training";
            return objects;
        }

        entry = readdir(dirPtr);
        while(entry != NULL) {
            if(entry->d_type == DT_DIR && entry->d_name[0] != '.') objects.push_back(make_pair(entry->d_name, std::vector<std::string>()));
            entry = readdir(dirPtr);
        }
        closedir(dirPtr);
        for(int i = 0; i < objects.size(); i++) {
            dirPtr = opendir((directory + objects[i].first).c_str());
            entry = readdir(dirPtr);
            while(entry != NULL) {
                if(entry->d_type != DT_DIR) objects[i].second.push_back(entry->d_name);
                entry = readdir(dirPtr);
            }
        }

        return objects;
    }
// ############################### Help Functions ##############################
    cv::Mat matToFloatRow(const cv::Mat& input) {
        cv::Mat res(1, input.rows*input.cols*attributes, CV_32FC1);
        int rows = input.rows;
        int cols = input.cols;
        for(int x=0; x < rows; x++){
            for (int y=0; y<cols; y++){
                res.at<float>(0,((x*cols + y)*attributes))      = float(input.at<cv::Vec3b>(x,y)[0]);
                //res.at<float>(0,((x*cols + y)*attributes + 1)) = float(input.at<cv::Vec3b>(x,y)[1]);
                //res.at<float>(0,((x*cols + y)*attributes + 2)) = float(input.at<cv::Vec3b>(x,y)[2]);
            }
        }
        return res;
    }
    void speakresult(std::string detectedobject){
        std::stringstream ss;

        ss<<"I see a " << detectedobject;
        std_msgs::String msg;
        msg.data=ss.str();
        espeak_pub.publish(msg);
    }

private:
    std::string color;
    int lastobjects[2];
    int alreadyseen[10];
    float Point[3];
    cv::PCA pca;
    ros::Publisher espeak_pub , evidence_pub, objectposition_pub;
    ros::NodeHandle nh;
    ros::Subscriber img_path_sub, imgposition_sub;
    static const float surenessfactor = 0.5;
    static const int neighborcount= 7;
    static const int sample_size_x = 100;
    static const int sample_size_y = 100;
    static const int attributes = 1;
    static const float pcaaccuracy = 0.99;
    static const bool save= false;
    static const bool load= true;
    std::map<int, std::string> intToDesc;
    std::string imagedir;
    cv::KNearest kc;
    cv::NormalBayesClassifier bc;
    image_transport::ImageTransport _it;
    image_transport::Subscriber img_sub;
    ros::Time lastobject;
    std_msgs::Header currentheader_;
    bool working;
    actionlib::SimpleActionServer<skeleton_markers::recognitionActionAction> server;
};


int main(int argc, char** argv){
    ros::init(argc, argv, "object_recognition");
    object_recognition object_rec;
    ros::Rate rate(1);
    while(ros::ok()){
        ros::spinOnce();
    }
}
